import json
from typing import Dict, List

from llama_index.core.base.llms.types import ChatMessage, ChatResponse, MessageRole
from pydantic import BaseModel

from .log_utils import get_logger
from .prompts import ORDER_PROMPT
from .token_counter import TokenCounter, TokenCounterCached
from .utils import add_lineno

logger = get_logger(__name__)

SYSTEM_PROMPT = r"""
You are an expert in SystemVerilog design.
You can always write SystemVerilog code with no syntax errors and always reach correct functionality.
"""

GENERATION_PROMPT = r"""
A simulation has failed for the rtl and testbench generated by other agents;
The related failed_sim_log was given below. The input_spec which the rtl and testbench should follow was also given below.
Please judge whether the TESTBENCH need to be modified.
If you think so, set tb_needs_fix = True, otherwise set tb_needs_fix = False.
Try to understand the requirements above and give reasoning steps in natural language to achieve it.

<input_spec>
{input_spec}
</input_spec>
<failed_sim_log>
{failed_sim_log}
</failed_sim_log>
<failed_rtl>
{failed_rtl}
</failed_rtl>
<failed_testbench>
{failed_testbench}
</failed_testbench>
"""

EXAMPLE_OUTPUT = {
    "reasoning": "All reasoning steps",
    "tb_needs_fix": False,
}


class TBOutputFormat(BaseModel):
    reasoning: str
    tb_needs_fix: bool


EXTRA_ORDER_PROMPT = r"""
Especially, FORCE SET tb_needs_fix to True if failed_sim_log says there is ANY syntax error in testbench(tb.sv),
Even if the syntax error looks not related to the failed test case or the testbench looks correct.
"""


class SimJudge:
    def __init__(
        self,
        token_counter: TokenCounter,
    ):
        self.token_counter = token_counter
        self.history: List[ChatMessage] = []

    def reset(self):
        self.history = []

    def generate(self, messages: List[ChatMessage]) -> ChatResponse:
        logger.info(f"Sim judge input message: {messages}")
        resp, token_cnt = self.token_counter.count_chat(messages)
        logger.info(f"Token count: {token_cnt}")
        logger.info(f"{resp.message.content}")
        return resp

    def get_init_prompt_messages(
        self,
        input_spec: str,
        failed_sim_log: str,
        failed_rtl: str,
        failed_testbench: str,
    ) -> List[ChatMessage]:
        ret = [
            ChatMessage(content=SYSTEM_PROMPT, role=MessageRole.SYSTEM),
            ChatMessage(
                content=GENERATION_PROMPT.format(
                    input_spec=input_spec,
                    failed_sim_log=failed_sim_log,
                    failed_rtl=add_lineno(failed_rtl),
                    failed_testbench=add_lineno(failed_testbench),
                ),
                role=MessageRole.USER,
            ),
        ]
        return ret

    def get_order_prompt_messages(self) -> List[ChatMessage]:
        return [
            ChatMessage(
                content=ORDER_PROMPT.format(
                    output_format="".join(json.dumps(EXAMPLE_OUTPUT, indent=4))
                    + EXTRA_ORDER_PROMPT
                ),
                role=MessageRole.USER,
            ),
        ]

    def parse_output(self, response: ChatResponse) -> TBOutputFormat:
        output_json_obj: Dict = json.loads(response.message.content, strict=False)
        return TBOutputFormat(
            reasoning=output_json_obj["reasoning"],
            tb_needs_fix=output_json_obj["tb_needs_fix"],
        )

    def chat(
        self,
        input_spec: str,
        failed_sim_log: str,
        failed_rtl: str,
        failed_testbench: str,
    ) -> bool:
        if isinstance(self.token_counter, TokenCounterCached):
            self.token_counter.set_enable_cache(False)
        self.history = []
        self.token_counter.set_cur_tag(self.__class__.__name__)
        self.history.extend(
            self.get_init_prompt_messages(
                input_spec, failed_sim_log, failed_rtl, failed_testbench
            )
        )
        self.history.extend(self.get_order_prompt_messages())
        response = self.generate(self.history)
        resp_obj = self.parse_output(response)
        return resp_obj.tb_needs_fix
